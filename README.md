# BERT Poetic

## What's this?

A collection of tools to explore poetry generation with a neural network
transformer language model.

## Line classifier

The poetry line classifier takes a window of lines of poetry as input and
predicts whether the line at the center of the window is a line of poetry.

This classifier is not intended to capture any profound truths vis-a-vis the
nature of poetry. It is intended to assist in identifying contiguous spans of
poetic text in the Project Gutenberg corpus.

### Line classifier dataset

To construct the annotated dataset, I used the heuristic rules defined in
Alison Parish's [gutenberg-poetry-corpus
project](https://github.com/aparrish/gutenberg-poetry-corpus) to annotate an
initial training set, then trained an intermediate classifier based on those
heuristic labels. This intermediate set generalized somewhat from the heuristic
model to improve accuracy. To construct the final training set, I sampled the
first, middle, and last hundred lines from each work in the Gutenberg Dammit
dataset with a `Subject` metadata field matching the pattern `^Poet.*`. This
sampling strategy is intended to capture a reasonable cross-section of the
corpus text while providing contiguity for the ease of annotation. The sample
consists of 123,143 lines total. I used the intermediate model to generate
initial predictions, then manually corrected classification errors.

The annotated dataset is stored in a TSV format where each line consists of a
label, padded Gutenberg Dammit ID number of the work, and (zero-indexed) line
number within the work. For example:

`0	00020	0`

To generate windowed data, run the following script, supplying the location of
the [Gutenberg Dammit](https://github.com/aparrish/gutenberg-dammit) archive
and the output file path where you want the output to be saved.

    python -m scripts.windowed_classifier_data <GD_ARCHIVE_PATH> data/line_classifier_annotations.tsv <OUTPUT_PATH>

For training, split the data into `train`, `validation` and `test` segments. I
used 0.6 for the `train` segment and held out 0.2 each for the `validation` and
`test` segments. Pass in the path where you saved your windowed data with the
previous step.

    python -m scripts.split <WINDOWED_DATA_PATH> 0.2

### Line classifier training

To train the model, run the following, supplying the paths of the splits
generated by the split script described in the dataset section above:

    python -m models.poetry_classifier --val-data <VAL_DATA_PATH> --test-data <TEST_DATA_PATH> --train-data <TRAIN_DATA_PATH>

### Line classifier predictions

To get line classifier predictions, run the following script:

    python -m inference.poetry_classifier_inference <GD_ARCHIVE_PATH> data/line_classifier_predictions.tsv --model-path <MODEL_PATH>

## Poetry segmenter

